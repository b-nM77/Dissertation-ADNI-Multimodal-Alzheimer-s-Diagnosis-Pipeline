{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a4fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSF Biomarker Baseline Pipeline — v2 (keeps original intact)\n",
    "# -----------------------------------------------------------\n",
    "# Run top-to-bottom. No CLI args.\n",
    "# What this does:\n",
    "# 1) Baseline selection using visit priority: bl/init > sc > m03 > m06 > m12 > m24 > later\n",
    "# 2) One row per PTID (earliest visit kept)\n",
    "# 3) NO dropping on Diagnosis (CSF file may not have labels). If a diagnosis column exists, some EDA plots are stratified by it.\n",
    "# 4) Compute CSF ratios (Tau/Abeta42, pTau/Abeta42, Abeta42/Abeta40 if columns exist)\n",
    "# 5) Save baseline Excel (with ratios): clinical_csf_baseline.xlsx\n",
    "# 6) EDA after ratios: histogram/KDE of ratios, correlation heatmap (incl. ratios), optional scatter matrix; violin/box by diagnosis only if diagnosis exists\n",
    "# 7) Imputation: MICE for numeric + IQR clipping (plausibility), mode for categorical/binary; save clinical_csf_imputed.xlsx\n",
    "# 8) Plots saved under data/processed/plots/csf and also displayed inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e89378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports, helpers, tokens\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    _HAS_SNS = True\n",
    "    sns.set_context(\"notebook\")\n",
    "except Exception:\n",
    "    _HAS_SNS = False\n",
    "\n",
    "# inline plotting\n",
    "%matplotlib inline\n",
    "SHOW_PLOTS = True\n",
    "\n",
    "# Visit priority (CogNID-style)\n",
    "VISIT_PRIORITY = {\n",
    "    \"bl\": 1, \"init\": 1,\n",
    "    \"sc\": 2, \"screening\": 2,\n",
    "    \"m03\": 3, \"month3\": 3, \"3m\": 3,\n",
    "    \"m06\": 4, \"month6\": 4, \"6m\": 4,\n",
    "    \"m12\": 5, \"month12\": 5, \"12m\": 5,\n",
    "    \"m24\": 6, \"month24\": 6,\n",
    "}\n",
    "\n",
    "# tokens for auto-detection\n",
    "PTID_TOKENS  = [\"ptid\", \"subject\", \"subject_id\", \"rid\"]\n",
    "VISIT_TOKENS = [\"visit\", \"visist\", \"phase\", \"timepoint\", \"timepoint_label\"]\n",
    "GENDER_TOKENS = [\"gender\", \"sex\"]\n",
    "AGE_TOKENS = [\"entry_age\", \"age\", \"ptage\", \"baselineage\"]\n",
    "\n",
    "# CSF biomarker tokens (flexible headers)\n",
    "TAU_TOKENS    = [\"total tau\", \"tau pg/ml\", \"t-tau\", \"ttau\", \"total_tau\"]\n",
    "PTAU_TOKENS   = [\"phospho tau\", \"p-tau\", \"ptau\", \"p_tau\"]\n",
    "ABETA42_TOKENS= [\"a beta 142\", \"abeta42\", \"aβ42\", \"abeta 42\", \"ab42\", \"a beta 1-42\"]\n",
    "ABETA40_TOKENS= [\"abeta40\", \"aβ40\", \"ab40\", \"a beta 1-40\"]\n",
    "\n",
    "# helpers\n",
    "\n",
    "def normalize_colnames(cols):\n",
    "    out = []\n",
    "    for c in cols:\n",
    "        c2 = str(c).strip()\n",
    "        c2 = re.sub(r\"\\s+\", \" \", c2)\n",
    "        out.append(c2)\n",
    "    return out\n",
    "\n",
    "def find_exact_col(df, tokens):\n",
    "    lcmap = {c.lower(): c for c in df.columns}\n",
    "    for t in tokens:\n",
    "        if t in lcmap:\n",
    "            return lcmap[t]\n",
    "    return None\n",
    "\n",
    "def find_contains_col(df, tokens):\n",
    "    for c in df.columns:\n",
    "        lc = c.lower()\n",
    "        for t in tokens:\n",
    "            if t in lc:\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "def parse_visit_priority(v):\n",
    "    if pd.isna(v):\n",
    "        return 999\n",
    "    s = str(v).strip().lower()\n",
    "    return VISIT_PRIORITY.get(s, 999)\n",
    "\n",
    "def drop_empty_columns(df, keep_cols=None):\n",
    "    keep_cols = set([k for k in (keep_cols or []) if k])\n",
    "    drop = []\n",
    "    for c in df.columns:\n",
    "        if c in keep_cols:\n",
    "            continue\n",
    "        if df[c].isna().all():\n",
    "            drop.append(c)\n",
    "    return df.drop(columns=drop), drop\n",
    "\n",
    "def standardize_yes_no(df):\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == object:\n",
    "            s = df[c].astype(str).str.strip().str.lower()\n",
    "            mask_yes = s.isin([\"yes\",\"y\",\"true\",\"1\"])\n",
    "            mask_no  = s.isin([\"no\",\"n\",\"false\",\"0\"])\n",
    "            df.loc[mask_yes, c] = \"Yes\"\n",
    "            df.loc[mask_no, c]  = \"No\"\n",
    "    return df\n",
    "\n",
    "def safe_filename(name: str) -> str:\n",
    "    return re.sub(r'[\\\\/*?:\"<>| ]+', \"_\", str(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b16c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (EDIT to your machine layout)\n",
    "PROJECT_ROOT = Path(\"/Users/madhurabn/Desktop/adni\")  # <-- change if needed\n",
    "input_path   = PROJECT_ROOT / \"data\" / \"raw\" / \"CSF biomarkers ADNI.xlsx\"\n",
    "outdir       = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "plots_dir    = outdir / \"plots\" / \"csf\"\n",
    "\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Paths set:\\n- input:\", input_path, \"\\n- out:\", outdir, \"\\n- plots:\", plots_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ea1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load, baseline-filter (one row per PTID), light tidy, map codes (NO diagnosis dropping here)\n",
    "xl = pd.ExcelFile(input_path)\n",
    "df = xl.parse(xl.sheet_names[0])\n",
    "df.columns = normalize_colnames(df.columns)\n",
    "\n",
    "ptid_col  = find_exact_col(df, PTID_TOKENS)\n",
    "visit_col = find_exact_col(df, VISIT_TOKENS)\n",
    "if ptid_col is None or visit_col is None:\n",
    "    raise ValueError(f\"Required columns not found. PTID={ptid_col}, VISIT={visit_col}\\nGot: {list(df.columns)}\")\n",
    "\n",
    "gender_col = find_contains_col(df, GENDER_TOKENS)\n",
    "age_col    = find_contains_col(df, AGE_TOKENS)\n",
    "\n",
    "# baseline by visit priority\n",
    "work = df.copy()\n",
    "work[\"_visit_priority\"] = work[visit_col].apply(parse_visit_priority)\n",
    "work_sorted = work.sort_values(by=[\"_visit_priority\"]).copy()\n",
    "baseline = work_sorted.drop_duplicates(subset=[ptid_col], keep=\"first\").copy()\n",
    "baseline.drop(columns=[\"_visit_priority\"], inplace=True)\n",
    "\n",
    "# light tidy\n",
    "baseline, dropped_empty = drop_empty_columns(baseline, keep_cols=[ptid_col, visit_col, gender_col])\n",
    "baseline = standardize_yes_no(baseline)\n",
    "\n",
    "print(\"Baseline shape:\", baseline.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c376ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect CSF columns and compute ratios if present\n",
    "\n",
    "def find_col(df, tokens):\n",
    "    return find_contains_col(df, tokens)\n",
    "\n",
    "col_tau   = find_col(baseline, TAU_TOKENS)\n",
    "col_ptau  = find_col(baseline, PTAU_TOKENS)\n",
    "col_ab42  = find_col(baseline, ABETA42_TOKENS)\n",
    "col_ab40  = find_col(baseline, ABETA40_TOKENS)\n",
    "\n",
    "print(\"Detected CSF biomarker columns:\\n - Total Tau:\", col_tau, \"\\n - p-Tau:\", col_ptau, \"\\n - Aβ42:\", col_ab42, \"\\n - Aβ40:\", col_ab40)\n",
    "\n",
    "# ratios\n",
    "if col_tau and col_ab42 and col_tau in baseline.columns and col_ab42 in baseline.columns:\n",
    "    baseline[\"Tau_over_Abeta42\"] = pd.to_numeric(baseline[col_tau], errors=\"coerce\") / pd.to_numeric(baseline[col_ab42], errors=\"coerce\")\n",
    "if col_ptau and col_ab42 and col_ptau in baseline.columns and col_ab42 in baseline.columns:\n",
    "    baseline[\"pTau_over_Abeta42\"] = pd.to_numeric(baseline[col_ptau], errors=\"coerce\") / pd.to_numeric(baseline[col_ab42], errors=\"coerce\")\n",
    "if col_ab42 and col_ab40 and col_ab42 in baseline.columns and col_ab40 in baseline.columns:\n",
    "    baseline[\"Abeta42_over_Abeta40\"] = pd.to_numeric(baseline[col_ab42], errors=\"coerce\") / pd.to_numeric(baseline[col_ab40], errors=\"coerce\")\n",
    "\n",
    "# save baseline (with ratios)\n",
    "baseline_xlsx = outdir / \"clinical_csf_baseline.xlsx\"\n",
    "baseline.to_excel(baseline_xlsx, index=False)\n",
    "print(\"Saved baseline with ratios ->\", baseline_xlsx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fb3405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick statistical summary after baseline + ratios\n",
    "print(\"\\n=== CSF Baseline Summary (after ratios) ===\")\n",
    "print(\"Shape:\", baseline.shape)\n",
    "\n",
    "# overall missingness\n",
    "total_missing = int(baseline.isna().sum().sum())\n",
    "print(\"Total missing cells:\", total_missing)\n",
    "\n",
    "# top missing columns\n",
    "miss_per_col = baseline.isna().sum().sort_values(ascending=False)\n",
    "print(\"\\nTop missing columns (first 15):\")\n",
    "print(miss_per_col.head(15))\n",
    "\n",
    "# basic describe for numeric columns\n",
    "num_desc = baseline.select_dtypes(include=[np.number]).describe().T\n",
    "print(\"\\nNumeric describe (head):\")\n",
    "print(num_desc.head(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b3f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA after ratios\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# 1) Histogram/KDE of each ratio\n",
    "ratio_cols = [c for c in [\"Tau_over_Abeta42\",\"pTau_over_Abeta42\",\"Abeta42_over_Abeta40\"] if c in baseline.columns]\n",
    "for c in ratio_cols:\n",
    "    series = pd.to_numeric(baseline[c], errors=\"coerce\").dropna()\n",
    "    if series.empty:\n",
    "        continue\n",
    "    plt.figure(figsize=(6,4))\n",
    "    if _HAS_SNS:\n",
    "        sns.histplot(series, bins=30, kde=True)\n",
    "        plt.title(f\"Histogram/KDE: {c}\")\n",
    "    else:\n",
    "        plt.hist(series, bins=30); plt.title(f\"Histogram: {c}\")\n",
    "    plt.tight_layout(); plt.savefig(plots_dir / f\"hist_{safe_filename(c)}.png\", dpi=150)\n",
    "    if SHOW_PLOTS: plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# 2) Correlation heatmap including ratios\n",
    "num_df = baseline.select_dtypes(include=[np.number]).copy()\n",
    "if not num_df.empty and _HAS_SNS:\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(num_df.corr(numeric_only=True), cmap=\"vlag\", center=0)\n",
    "    plt.title(\"Correlation heatmap (incl. ratios)\")\n",
    "    plt.tight_layout(); plt.savefig(plots_dir / \"corr_heatmap_csf.png\", dpi=150)\n",
    "    if SHOW_PLOTS: plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# 3) Optional scatter matrix (may be heavy on large datasets)\n",
    "try:\n",
    "    sm_cols = [c for c in ratio_cols if c in baseline.columns][:4]  # limit to first few ratios\n",
    "    if len(sm_cols) >= 2:\n",
    "        scatter_matrix(baseline[sm_cols].dropna(), figsize=(8,8), diagonal='kde')\n",
    "        plt.suptitle(\"Scatter matrix of CSF ratios\", y=1.02)\n",
    "        plt.tight_layout(); plt.savefig(plots_dir / \"scatter_matrix_ratios.png\", dpi=150)\n",
    "        if SHOW_PLOTS: plt.show()\n",
    "        plt.close()\n",
    "except Exception as e:\n",
    "    print(\"Scatter matrix skipped:\", e)\n",
    "\n",
    "# 4) If a diagnosis-like column exists, violin/box by diagnosis\n",
    "# (will auto-detect a diagnosis-like column if present, but won't error if missing)\n",
    "possible_diag = [\"diagnosis\",\"diag\",\"dx\",\"dx_bl\",\"diagnosis_bl\"]\n",
    "diag_guess = None\n",
    "for cand in possible_diag:\n",
    "    c0 = find_contains_col(baseline, [cand])\n",
    "    if c0:\n",
    "        diag_guess = c0; break\n",
    "\n",
    "if diag_guess:\n",
    "    for c in ratio_cols:\n",
    "        if _HAS_SNS:\n",
    "            plt.figure(figsize=(7,4))\n",
    "            sns.violinplot(data=baseline, x=diag_guess, y=c, inner=\"quartile\", cut=0)\n",
    "            plt.title(f\"{c} by {diag_guess}\")\n",
    "            plt.tight_layout(); plt.savefig(plots_dir / f\"violin_{safe_filename(c)}_by_{safe_filename(diag_guess)}.png\", dpi=150)\n",
    "            if SHOW_PLOTS: plt.show()\n",
    "            plt.close()\n",
    "        else:\n",
    "            # fallback to boxplot\n",
    "            plt.figure(figsize=(7,4))\n",
    "            groups, labels = [], []\n",
    "            for dlab, sub in baseline.groupby(diag_guess):\n",
    "                vals = pd.to_numeric(sub[c], errors=\"coerce\").dropna().values\n",
    "                if len(vals): groups.append(vals); labels.append(str(dlab))\n",
    "            if groups:\n",
    "                plt.boxplot(groups, labels=labels)\n",
    "                plt.title(f\"{c} by {diag_guess}\")\n",
    "                plt.tight_layout(); plt.savefig(plots_dir / f\"box_{safe_filename(c)}_by_{safe_filename(diag_guess)}.png\", dpi=150)\n",
    "                if SHOW_PLOTS: plt.show()\n",
    "                plt.close()\n",
    "\n",
    "print(\"EDA complete. Plots saved to:\", plots_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c3a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation: MICE (numeric) + IQR clipping; categorical via mode; single output Excel\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa: F401\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "\n",
    "# copies\n",
    "df_before = baseline.copy()\n",
    "df_after  = baseline.copy()\n",
    "\n",
    "# detect numeric vs categorical\n",
    "obj_like = df_after.select_dtypes(include=['object','category']).columns.tolist()\n",
    "num_like = df_after.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# simple heuristic for binary-like numeric (keep for mode imputation)\n",
    "def _is_binary_series(s: pd.Series) -> bool:\n",
    "    vals = s.dropna().unique()\n",
    "    if len(vals) == 0: return False\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        try:\n",
    "            return set(pd.Series(vals).astype(float).astype(int)).issubset({0,1})\n",
    "        except Exception:\n",
    "            return False\n",
    "    low = pd.Series(vals).astype(str).str.strip().str.lower()\n",
    "    return low.isin({\"yes\",\"no\",\"y\",\"n\",\"true\",\"false\",\"0\",\"1\"}).all()\n",
    "\n",
    "binary_cols_num = [c for c in num_like if _is_binary_series(df_after[c])]\n",
    "cont_cols = [c for c in num_like if c not in binary_cols_num]\n",
    "cat_cols = list(obj_like)\n",
    "\n",
    "# 1) Categorical/binary -> mode imputation (most_frequent)\n",
    "cat_bin_to_impute = [c for c in cat_cols + binary_cols_num if df_after[c].isna().any()]\n",
    "if cat_bin_to_impute:\n",
    "    mode_imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "    df_after[cat_bin_to_impute] = mode_imp.fit_transform(df_after[cat_bin_to_impute])\n",
    "\n",
    "# 2) Continuous -> MICE\n",
    "if cont_cols:\n",
    "    mice = IterativeImputer(random_state=42, sample_posterior=False, max_iter=10, initial_strategy=\"median\")\n",
    "    df_after[cont_cols] = mice.fit_transform(df_after[cont_cols])\n",
    "\n",
    "    # --- IQR clipping to keep values clinically plausible ---\n",
    "    for c in cont_cols:\n",
    "        series = pd.to_numeric(df_after[c], errors=\"coerce\")\n",
    "        q1 = series.quantile(0.25)\n",
    "        q3 = series.quantile(0.75)\n",
    "        if pd.isna(q1) or pd.isna(q3):\n",
    "            continue\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        # Non-negative biomarker hint\n",
    "        nonneg_hint = any(kw in c.lower() for kw in [\"tau\",\"beta\",\"abeta\",\"aβ\",\"pg_ml\",\"csf\"]) or c.lower().endswith((\"42\",\"40\"))\n",
    "        clipped = series.clip(lower=lower, upper=upper)\n",
    "        if nonneg_hint:\n",
    "            clipped = clipped.clip(lower=0)\n",
    "        df_after[c] = clipped\n",
    "\n",
    "# enforce binary back to int 0/1 (if numeric)\n",
    "for c in binary_cols_num:\n",
    "    if pd.api.types.is_numeric_dtype(df_after[c]):\n",
    "        df_after[c] = pd.to_numeric(df_after[c], errors=\"coerce\").round().clip(0,1).astype(\"Int64\")\n",
    "\n",
    "# Save outputs\n",
    "baseline_out = outdir / \"clinical_csf_baseline.xlsx\"  # already saved above as well\n",
    "imputed_out  = outdir / \"clinical_csf_imputed.xlsx\"\n",
    "\n",
    "df_after.to_excel(imputed_out, index=False)\n",
    "print(\"Saved imputed file ->\", imputed_out)\n",
    "\n",
    "# Quick post-imputation summary\n",
    "print(\"\\n=== MICE (numeric) + IQR clip + Mode (categorical) Summary ===\")\n",
    "print(\"Rows:\", df_after.shape[0], \"Cols:\", df_after.shape[1])\n",
    "print(\"Missing before:\", int(df_before.isna().sum().sum()))\n",
    "print(\"Missing after :\", int(df_after.isna().sum().sum()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
