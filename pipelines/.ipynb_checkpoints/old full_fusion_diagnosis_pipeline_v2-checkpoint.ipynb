{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b25586cb",
   "metadata": {},
   "source": [
    "\n",
    "# Full-Fusion Diagnosis Pipeline (CV + ADASYN + RF/XGB/SVM + Stacking)\n",
    "This notebook:\n",
    "- Loads your **fusion_master.xlsx** (or any fusion file you point to)\n",
    "- Drops rows with empty **Diagnosis**\n",
    "- Preprocesses features (numeric + one-hot for any leftover categoricals)\n",
    "- Handles **class imbalance with ADASYN inside CV**\n",
    "- Trains **RandomForest, XGBoost, SVM (RBF)**, and a **Stacking Ensemble**\n",
    "- Reports **Accuracy, Macro-F1, ROC-AUC (OvR), Confusion Matrix**\n",
    "- Saves figures/metrics under `./diagnostics_out/`\n",
    "\n",
    "> Tip: Run cell-by-cell the first time to confirm paths and column names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacdb091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === User config ===\n",
    "FUSION_XLSX = r\"./fusion_master.xlsx\"  # <- change if stored elsewhere\n",
    "OUTDIR = Path(\"./diagnostics_out\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Optional: force column names for id/target if auto-detect fails\n",
    "FORCE_PTID_COL = None          # e.g., \"PTID\"\n",
    "FORCE_DIAG_COL = None          # e.g., \"Diagnosis\"\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "N_FOLDS = 5\n",
    "\n",
    "print(\"Output dir:\", OUTDIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628e1883",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Modeling / preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Sampler (inside CV)\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "except Exception as e:\n",
    "    print(\"xgboost not available:\", e)\n",
    "    HAS_XGB = False\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"notebook\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a6a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Load fusion file ===\n",
    "df = pd.read_excel(FUSION_XLSX)\n",
    "print(\"Loaded fusion:\", df.shape)\n",
    "\n",
    "# --- normalize column names (keep original too) ---\n",
    "orig_cols = df.columns.tolist()\n",
    "df.columns = [str(c).strip() for c in df.columns]\n",
    "\n",
    "# --- detect PTID and Diagnosis ---\n",
    "def find_col(cands, cols):\n",
    "    cols_lower = {c.lower(): c for c in cols}\n",
    "    for tok in cands:\n",
    "        for c in cols:\n",
    "            if tok == c.lower():\n",
    "                return c\n",
    "        for c in cols:\n",
    "            if tok in c.lower():\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "ptid_col = FORCE_PTID_COL or find_col([\"ptid\",\"rid\",\"subject\",\"id\"], df.columns)\n",
    "diag_col = FORCE_DIAG_COL or find_col([\"diagnosis\",\"dx\",\"diag\",\"group\"], df.columns)\n",
    "\n",
    "print(\"Detected PTID:\", ptid_col)\n",
    "print(\"Detected Diagnosis:\", diag_col)\n",
    "\n",
    "if ptid_col is None or diag_col is None:\n",
    "    raise ValueError(\"Could not detect PTID or Diagnosis column. Set FORCE_PTID_COL / FORCE_DIAG_COL.\")\n",
    "\n",
    "# Drop rows with empty diagnosis\n",
    "before = df.shape[0]\n",
    "df = df[~df[diag_col].isna()].copy()\n",
    "after = df.shape[0]\n",
    "print(f\"Dropped rows with empty Diagnosis: {before-after}\")\n",
    "\n",
    "# Quick peek\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f055dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Split X/y and build preprocessors ===\n",
    "y_raw = df[diag_col].astype(str)\n",
    "\n",
    "# Encode labels (CN/MCI/Dementia -> 0/1/2 etc.)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_raw)\n",
    "label_map = {i: cls for i, cls in enumerate(le.classes_)}\n",
    "print(\"Label mapping:\", label_map)\n",
    "\n",
    "# Drop obvious meta columns from X\n",
    "drop_like = {diag_col, ptid_col, \"visit\", \"VISCODE\", \"viscode\", \"VisCode\"}\n",
    "X = df.drop(columns=[c for c in df.columns if c in drop_like], errors=\"ignore\")\n",
    "\n",
    "# Identify dtypes\n",
    "cat_cols = X.select_dtypes(include=[\"object\",\"category\",\"bool\"]).columns.tolist()\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols),\n",
    "        (\"num\", Pipeline(steps=[(\"scaler\", StandardScaler())]), num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "print(f\"X shape: {X.shape} -> numeric:{len(num_cols)} | categorical:{len(cat_cols)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165e0c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Helpers: evaluation & plotting ===\n",
    "def evaluate_cv(model_name, estimator, X, y, cv):\n",
    "    \"\"\"Return metrics dict and also save plots.\"\"\"\n",
    "    # cross_val_predict gives out-of-fold predictions\n",
    "    y_pred = cross_val_predict(estimator, X, y, cv=cv, method=None, n_jobs=-1)\n",
    "\n",
    "    # For ROC-AUC need probabilities/decision function\n",
    "    proba_supported = hasattr(estimator, \"predict_proba\")\n",
    "    decf_supported  = hasattr(estimator, \"decision_function\")\n",
    "    if proba_supported:\n",
    "        y_score = cross_val_predict(estimator, X, y, cv=cv, method=\"predict_proba\", n_jobs=-1)\n",
    "    elif decf_supported:\n",
    "        y_score = cross_val_predict(estimator, X, y, cv=cv, method=\"decision_function\", n_jobs=-1)\n",
    "        # map decision_function outputs to [0,1] via softmax-ish if multiclass\n",
    "        if y_score.ndim == 1:\n",
    "            # binary margin -> pseudo proba\n",
    "            from sklearn.utils.extmath import softmax\n",
    "            y_score = np.vstack([1/(1+np.exp(y_score)), 1-1/(1+np.exp(y_score))]).T\n",
    "        else:\n",
    "            from sklearn.utils.extmath import softmax\n",
    "            y_score = softmax(y_score)\n",
    "    else:\n",
    "        y_score = None\n",
    "\n",
    "    acc  = accuracy_score(y, y_pred)\n",
    "    f1m  = f1_score(y, y_pred, average=\"macro\")\n",
    "\n",
    "    roc = None\n",
    "    if y_score is not None:\n",
    "        try:\n",
    "            roc = roc_auc_score(y, y_score, multi_class=\"ovr\", average=\"macro\")\n",
    "        except Exception:\n",
    "            roc = None\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y, y_pred, labels=np.unique(y))\n",
    "\n",
    "    # Save confusion matrix plot\n",
    "    plt.figure(figsize=(4.5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=[label_map[i] for i in np.unique(y)],\n",
    "                yticklabels=[label_map[i] for i in np.unique(y)])\n",
    "    plt.title(f\"{model_name} — Confusion Matrix (CV)\")\n",
    "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTDIR / f\"{model_name}_confusion_matrix.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    # Save classification report\n",
    "    report = classification_report(y, y_pred, target_names=[label_map[i] for i in np.unique(y)])\n",
    "    with open(OUTDIR / f\"{model_name}_classification_report.txt\", \"w\") as f:\n",
    "        f.write(report)\n",
    "\n",
    "    # (Optional) ROC curves: multi-class OvR (only if y_score)\n",
    "    if y_score is not None and y_score.ndim > 1:\n",
    "        from sklearn.preprocessing import label_binarize\n",
    "        from sklearn.metrics import RocCurveDisplay\n",
    "        classes = np.unique(y)\n",
    "        y_bin = label_binarize(y, classes=classes)\n",
    "        plt.figure(figsize=(6,5))\n",
    "        for i, cls in enumerate(classes):\n",
    "            try:\n",
    "                RocCurveDisplay.from_predictions(y_true=y_bin[:, i], y_pred=y_score[:, i], name=f\"Class {label_map[cls]}\")\n",
    "            except Exception:\n",
    "                pass\n",
    "        plt.title(f\"{model_name} — ROC (OvR, CV)\")\n",
    "        plt.tight_layout(); plt.savefig(OUTDIR / f\"{model_name}_roc_ovr.png\", dpi=150); plt.show()\n",
    "\n",
    "    metrics = {\n",
    "        \"model\": model_name,\n",
    "        \"accuracy\": acc,\n",
    "        \"macro_f1\": f1m,\n",
    "        \"roc_auc_ovr_macro\": roc\n",
    "    }\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76619f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === CV & estimators (ADASYN inside pipeline) ===\n",
    "cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "estimators = {}\n",
    "\n",
    "# RandomForest\n",
    "estimators[\"RF\"] = ImbPipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"adasyn\", ADASYN(random_state=RANDOM_STATE)),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=400, max_depth=None, n_jobs=-1, random_state=RANDOM_STATE, class_weight=None\n",
    "    ))\n",
    "])\n",
    "\n",
    "# SVM (RBF)\n",
    "estimators[\"SVM_RBF\"] = ImbPipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"adasyn\", ADASYN(random_state=RANDOM_STATE)),\n",
    "    (\"clf\", SVC(C=5.0, kernel=\"rbf\", gamma=\"scale\", probability=True, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "# XGB (if available)\n",
    "if HAS_XGB:\n",
    "    estimators[\"XGB\"] = ImbPipeline(steps=[\n",
    "        (\"prep\", preprocess),\n",
    "        (\"adasyn\", ADASYN(random_state=RANDOM_STATE)),\n",
    "        (\"clf\", XGBClassifier(\n",
    "            n_estimators=600, max_depth=4, learning_rate=0.05, subsample=0.9, colsample_bytree=0.9,\n",
    "            objective=\"multi:softprob\", eval_metric=\"mlogloss\", random_state=RANDOM_STATE\n",
    "        ))\n",
    "    ])\n",
    "else:\n",
    "    print(\"XGB not available: skipping XGB model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f16994",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Stacking Ensemble (RF + SVM + optional XGB) ===\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "base_estimators = []\n",
    "base_estimators.append((\"rf\", estimators[\"RF\"]))\n",
    "base_estimators.append((\"svm\", estimators[\"SVM_RBF\"]))\n",
    "if \"XGB\" in estimators:\n",
    "    base_estimators.append((\"xgb\", estimators[\"XGB\"]))\n",
    "\n",
    "# Note: To stack imblearn pipelines, we build meta-features via probabilities.\n",
    "# We'll do a simple approach: train Stacking on preprocessed data with ADASYN inside\n",
    "stack_final = LogisticRegression(max_iter=200, multi_class=\"ovr\")\n",
    "\n",
    "stack = StackingClassifier(\n",
    "    estimators=[(name, est) for name, est in base_estimators],\n",
    "    final_estimator=stack_final,\n",
    "    stack_method=\"predict_proba\",\n",
    "    passthrough=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "estimators[\"STACK\"] = stack\n",
    "print(\"Models prepared:\", list(estimators.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3fc57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Evaluate all models ===\n",
    "all_metrics = []\n",
    "for name, est in estimators.items():\n",
    "    print(f\"\\n=== Evaluating: {name} ===\")\n",
    "    m = evaluate_cv(name, est, X, y, cv)\n",
    "    print(m)\n",
    "    all_metrics.append(m)\n",
    "\n",
    "metrics_df = pd.DataFrame(all_metrics).sort_values(by=[\"macro_f1\",\"accuracy\"], ascending=False)\n",
    "display(metrics_df)\n",
    "metrics_df.to_csv(OUTDIR / \"cv_metrics_summary.csv\", index=False)\n",
    "print(\"\\nSaved metrics to:\", OUTDIR / \"cv_metrics_summary.csv\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
